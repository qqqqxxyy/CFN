{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class apple():\n",
    "    def __init__(self):\n",
    "        self.a = 'b'\n",
    "        self.ou = base()\n",
    "    def oo(self):\n",
    "        self.ou.oput(self)\n",
    "\n",
    "class base():\n",
    "    def __init_(self):\n",
    "        pass\n",
    "    def oput(self,m):\n",
    "        print(m.a)\n",
    "\n",
    "a = apple()\n",
    "a.oo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import osj\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from BigGAN.gan_load import make_big_gan\n",
    "from utils.utils import to_image\n",
    "from gan_mask_gen import MaskGenerator, MaskSynthesizing\n",
    "from train_segmentation import TrainParams\n",
    "from test_frame import TestParams_jupyter\n",
    "from visualization import draw_with_mask\n",
    "from postprocessing import connected_components_filter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visulization of Segment map and CAM map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from UNet.unet_cam import UNet_cam_v5 as UNet_cam\n",
    "from data import SegFileDataset\n",
    "from postprocessing import SegmentationInference, Threshold\n",
    "from metrics import F_max, IoU, accuracy, model_metrics,Localization\n",
    "from visualization import overlayed\n",
    "from data import TestDataset\n",
    "import ipdb\n",
    "from postprocessing import CAMInference\n",
    "\n",
    "import cv2\n",
    "#模型准备\n",
    "%matplotlib inline\n",
    "unet_load_paths = '/home/qxy/Desktop/BigGan/weight_result/results/trained_weight/000122_result.pth'\n",
    "unet = UNet_cam().eval()\n",
    "unet.load_state_dict(torch.load(unet_load_paths))\n",
    "unet.eval()\n",
    "\n",
    "batch_size = 1\n",
    "param = TestParams_jupyter()\n",
    "\n",
    "# target_ds = TestDataset(param.image_root_dir,param.image_property_dir)\n",
    "target_ds = SegFileDataset(param,crop=False,size=128)\n",
    "\n",
    "segmentation_dl = torch.utils.data.DataLoader(target_ds, batch_size, shuffle=False)\n",
    "\n",
    "img,label = target_ds[3000]\n",
    "\n",
    "mask_pre = CAMInference(unet)(img.unsqueeze(0),label=200)\n",
    "\n",
    "plt.figure(figsize=(3,1),dpi=450)\n",
    "# image = make_grid(torch.clamp(mask_pre, -1, 1), nrow=batch_size, padding=5)\n",
    "# print(mask_pre.shape)\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis('off')\n",
    "\n",
    "# image=to_image(image,True)\n",
    "# plt.imshow(image)\n",
    "# # image=to_image(imgs_grid,True)\n",
    "image = (mask_pre - mask_pre.min()) / (mask_pre.max() - mask_pre.min())\n",
    "image = (255 * image).squeeze().cpu().detach().numpy()\n",
    "image = image.astype(np.uint8)\n",
    "\n",
    "image1=cv2.applyColorMap(image, cv2.COLORMAP_JET)\n",
    "print(image1.shape)\n",
    "\n",
    "image1 = image1[:,:,[2,1,0]]\n",
    "plt.imshow(image1)\n",
    "plt.subplot(1,2,2)\n",
    "images = to_image(img)\n",
    "plt.imshow(images)\n",
    "plt.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from UNet.unet_cam import UNet_cam_v5 as UNet_cam\n",
    "from data import SegFileDataset\n",
    "from postprocessing import SegmentationInference, Threshold\n",
    "from metrics import F_max, IoU, accuracy, model_metrics,Localization\n",
    "from visualization import overlayed\n",
    "from data import TestDataset\n",
    "import ipdb\n",
    "from postprocessing import CAMInference\n",
    "import cv2\n",
    "from torchvision.utils import make_grid\n",
    "from visualization import overlayed\n",
    "from utils.utils import to_image\n",
    "batch_size = 1\n",
    "param = TestParams_jupyter()\n",
    "\n",
    "unet_load_paths = '/home/qxy/Desktop/BigGan/weight_result/results/trained_weight/000122_result.pth'\n",
    "unet = UNet_cam().eval()\n",
    "unet.load_state_dict(torch.load(unet_load_paths))\n",
    "unet.eval()\n",
    "\n",
    "target_ds = SegFileDataset(param,crop=False,size=None)\n",
    "img,mask = target_ds[789]\n",
    "img = img.unsqueeze(0)\n",
    "mask_prediction = SegmentationInference(unet, resize_to=128)(img) > 0.8\n",
    "\n",
    "plt.figure(figsize=(1, 3.), dpi=450)\n",
    "imgs_grid = make_grid(torch.clamp(img, -1, 1), nrow=batch_size, padding=5)\n",
    "plt.imshow(to_image(overlayed(img, mask_prediction), True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visulization of CAM classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from UNet.unet_cam import UNet_cam_v4 as UNet_cam\n",
    "from data import SegFileDataset\n",
    "from postprocessing import SegmentationInference, Threshold\n",
    "from metrics import F_max, IoU, accuracy, model_metrics,Localization\n",
    "from visualization import overlayed\n",
    "from data import TestDataset\n",
    "import ipdb\n",
    "\n",
    "unet_load_paths = '/home/qxy/Desktop/BigGan/weight_result/results/trained_weight/000103_result.pth'\n",
    "unet = UNet_cam().eval()\n",
    "unet.load_state_dict(torch.load(unet_load_paths))\n",
    "unet.eval()\n",
    "\n",
    "batch_size = 1\n",
    "param = TestParams_jupyter()\n",
    "\n",
    "target_ds = TestDataset(param.image_root_dir,param.image_property_dir)\n",
    "segmentation_dl = torch.utils.data.DataLoader(target_ds, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from postprocessing import CAMInference\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "img,label = target_ds[300]\n",
    "\n",
    "mask_pre = CAMInference(unet)(img.unsqueeze(0),label)\n",
    "print(mask_pre.shape)\n",
    "plt.figure(figsize=(3,1),dpi=450)\n",
    "# image = make_grid(torch.clamp(mask_pre, -1, 1), nrow=batch_size, padding=5)\n",
    "# print(mask_pre.shape)\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis('off')\n",
    "\n",
    "# image=to_image(image,True)\n",
    "# plt.imshow(image)\n",
    "# # image=to_image(imgs_grid,True)\n",
    "image = (mask_pre - mask_pre.min()) / (mask_pre.max() - mask_pre.min())\n",
    "image = (255 * image).squeeze().cpu().detach().numpy()\n",
    "image = image.astype(np.uint8)\n",
    "print(image.shape)\n",
    "image1=cv2.applyColorMap(image, cv2.COLORMAP_JET)\n",
    "plt.imshow(image1)\n",
    "plt.subplot(1,2,2)\n",
    "images = to_image(img)\n",
    "plt.imshow(images)\n",
    "plt.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = to_image(img)\n",
    "#print(images.shape)\n",
    "plt.imshow(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from UNet.unet_model import UNet\n",
    "from data import SegFileDataset\n",
    "from postprocessing import SegmentationInference, Threshold\n",
    "from metrics import F_max, IoU, accuracy, model_metrics,Localization\n",
    "from visualization import overlayed\n",
    "\n",
    "import ipdb\n",
    "unet_load_paths = '/home/qxy/Desktop/BigGan/weight_result/results/trained_weight/000008_result.pth'\n",
    "unet = UNet().cuda().eval()\n",
    "unet.load_state_dict(torch.load(unet_load_paths, map_location='cpu'))\n",
    "unet.cuda().eval()\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "# CUB_imgs_dir = '/home/qxy/Desktop/datasets/CUB/data'\n",
    "# CUB_masks_dir = '/home/qxy/Desktop/datasets/CUB/segmentation'\n",
    "# image_prop = '/home/qxy/Desktop/datasets/CUB/data_annotation/'+\\\n",
    "#             'CUB_WSOL/test_list.json'\n",
    "param = TestParams_jupyter()\n",
    "\n",
    "target_ds = SegFileDataset(param,crop=False, size=None)\n",
    "segmentation_dl = torch.utils.data.DataLoader(target_ds, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Raw model:\\n{}'.format(\n",
    "    model_metrics(Threshold(unet, resize_to=128), \\\n",
    "                  segmentation_dl, stats=(Localization,) )))\n",
    "# print('Thresholded:\\n{}'.format(\n",
    "#     model_metrics(Threshold(unet, thr=0.5, resize_to=128), segmentation_dl, stats=(IoU, accuracy))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'localization'\n",
    "print(a.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from BigGAN.gan_load import make_big_gan\n",
    "from utils.utils import to_image\n",
    "from gan_mask_gen import MaskGenerator, MaskSynthesizing\n",
    "from train_segmentation import TrainParams_jupyter\n",
    "from visualization import draw_with_mask\n",
    "from postprocessing import connected_components_filter\n",
    "import ipdb\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "biggan_path = '/home/qxy/Desktop/BigGan/weight_result/weights/BigBiGAN_x1.pth'\n",
    "bg_path = '/home/qxy/Desktop/BigGan/weight_result/weights/bg_direction.pth'\n",
    "G = make_big_gan(biggan_path).cuda().eval()\n",
    "bg_direction = torch.load(bg_path).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "params = TrainParams_jupyter(batch_size=16,)\n",
    "# z = torch.randn([params.batch_size, G.dim_z]).cuda()\n",
    "embedding_path = '/home/qxy/Desktop/BigGan/weight_result/embeddings/BigBiGAN_ImageNet_z.npy'\n",
    "embedding_cls_path = '/home/qxy/Desktop/BigGan/weight_result/embeddings/BigBiGAN_CUB_WSOL_train_z_cls.npy'\n",
    "z = torch.from_numpy(np.load(embedding_path)).cuda()[[x for x in range(0, 974445)]]\n",
    "z_cls = torch.from_numpy(np.load(embedding_cls_path)).cuda()[[0,100,1000,500,1500,2500,300,450]]#[0:30]\n",
    "\n",
    "mg = MaskGenerator(G, bg_direction, params, zs=z,zs_cls=z_cls,\n",
    "                       mask_postprocessing=(connected_components_filter,))\n",
    "mg.cuda()\n",
    "\n",
    "img, ref = mg()\n",
    "draw_with_mask(img, [ref.unsqueeze(1)], names=[''], horizontal=False)\n",
    "# print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from BigGAN.gan_load import make_big_gan\n",
    "from utils.utils import to_image\n",
    "from gan_mask_gen import MaskGenerator, MaskSynthesizing\n",
    "from train_segmentation import TrainParams\n",
    "from test_frame import TestParams_jupyter\n",
    "from visualization import draw_with_mask\n",
    "from postprocessing import connected_components_filter\n",
    "\n",
    "from random import randint\n",
    "from UNet.unet_cam import UNet_cam_v4 as UNet_cam\n",
    "from data import SegFileDataset\n",
    "from postprocessing import SegmentationInference, Threshold\n",
    "from metrics import F_max, IoU, accuracy, model_metrics,Localization\n",
    "from visualization import overlayed\n",
    "from data import TestDataset\n",
    "\n",
    "\n",
    "import ipdb\n",
    "unet_load_paths = '/home/qxy/Desktop/BigGan/weight_result/results/trained_weight/000103_result.pth'\n",
    "unet = UNet_cam().eval()\n",
    "unet.load_state_dict(torch.load(unet_load_paths))\n",
    "unet.eval()\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "# CUB_imgs_dir = '/home/qxy/Desktop/datasets/CUB/data'\n",
    "# CUB_masks_dir = '/home/qxy/Desktop/datasets/CUB/segmentation'\n",
    "# image_prop = '/home/qxy/Desktop/datasets/CUB/data_annotation/'+\\\n",
    "#             'CUB_WSOL/test_list.json'\n",
    "param = TestParams_jupyter()\n",
    "\n",
    "target_ds = SegFileDataset(param,crop=False, size=None)\n",
    "segmentation_dl = torch.utils.data.DataLoader(target_ds, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ct = 400\n",
    "scale =5\n",
    "mask_prediction = []\n",
    "mask = []\n",
    "with torch.no_grad():\n",
    "    img = []\n",
    "    label = []\n",
    "    #ipdb.set_trace()\n",
    "\n",
    "    for i in range(ct,ct+5):\n",
    "        #ipdb.set_trace()\n",
    "        #img[i-ct], mask[i-ct] = target_ds[i]#[randint(0, len(target_ds))]\n",
    "        img_tmp,mask_tmp = target_ds[i]\n",
    "        img.append(img_tmp)\n",
    "        mask.append(mask_tmp)\n",
    "        img_tmp, mask_tmp = img[i-ct].unsqueeze(0), mask[i-ct].unsqueeze(0)\n",
    "        print(img_tmp.shape)\n",
    "        ipdb.set_trace()\n",
    "        mask_prediction.append( SegmentationInference(unet, resize_to=128)(img_tmp) > 0.5 )\n",
    "    ct+=5\n",
    "\n",
    "plt.figure(figsize=(3, 5.), dpi=450)\n",
    "for i in range(scale):\n",
    "    imgs_grid = make_grid(torch.clamp(img[i], -1, 1), nrow=batch_size, padding=5)\n",
    "\n",
    "    print(i)\n",
    "    plt.subplot(3,6,1+i*3)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(to_image(imgs_grid, True))\n",
    "    plt.subplot(3,6,2+i*3)\n",
    "    plt.axis('off')\n",
    "    plt.title('Ground truth',fontsize=5)\n",
    "    plt.imshow(to_image(overlayed(img[i], mask[i], channel=0), True))\n",
    "    plt.subplot(3,6,3+i*3)\n",
    "    plt.axis('off')\n",
    "    plt.title('Prediction',fontsize=5)\n",
    "    plt.imshow(to_image(overlayed(img[i], mask_prediction[i]), True))\n",
    "\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from postprocessing import CAMInference\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "img,label = target_ds[3006]\n",
    "\n",
    "mask_pre = CAMInference(unet)(img.unsqueeze(0),label)\n",
    "print(mask_pre.shape)\n",
    "plt.figure(figsize=(3,1),dpi=450)\n",
    "# image = make_grid(torch.clamp(mask_pre, -1, 1), nrow=batch_size, padding=5)\n",
    "# print(mask_pre.shape)\n",
    "plt.subplot(1,1,1)\n",
    "plt.axis('off')\n",
    "\n",
    "# image=to_image(image,True)\n",
    "# plt.imshow(image)\n",
    "# # image=to_image(imgs_grid,True)\n",
    "image = (mask_pre - mask_pre.min()) / (mask_pre.max() - mask_pre.min())\n",
    "image = (255 * image).squeeze().cpu().detach().numpy()\n",
    "image = image.astype(np.uint8)\n",
    "print(image.shape)\n",
    "image1=cv2.applyColorMap(image, cv2.COLORMAP_JET)\n",
    "\n",
    "plt.imshow(image1)\n",
    "plt.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#t = 500\n",
    "scale =5\n",
    "with torch.no_grad():\n",
    "    img = []\n",
    "    label = []\n",
    "    CAMs = []\n",
    "    #ipdb.set_trace()\n",
    "\n",
    "    for i in range(ct,ct+5):\n",
    "        #ipdb.set_trace()\n",
    "        #img[i-ct], mask[i-ct] = target_ds[i]#[randint(0, len(target_ds))]\n",
    "        img_tmp,label_tmp = target_ds[i]\n",
    "        img.append(img_tmp)\n",
    "        label.append(label_tmp)\n",
    "        img_tmp, label_tmp = img[i-ct].cuda().unsqueeze(0), label[i-ct].cuda().unsqueeze(0)\n",
    "        mask_prediction.append( SegmentationInference(unet, resize_to=128)(img_tmp) > 0.5 )\n",
    "    ct+=5\n",
    "\n",
    "plt.figure(figsize=(3, 5.), dpi=450)\n",
    "for i in range(scale):\n",
    "    imgs_grid = make_grid(torch.clamp(img[i], -1, 1), nrow=batch_size, padding=5)\n",
    "\n",
    "    print(i)\n",
    "    plt.subplot(3,6,1+i*3)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(to_image(imgs_grid, True))\n",
    "    plt.subplot(3,6,2+i*3)\n",
    "    plt.axis('off')\n",
    "    plt.title('Ground truth',fontsize=5)\n",
    "    plt.imshow(to_image(overlayed(img[i], mask[i], channel=0), True))\n",
    "    plt.subplot(3,6,3+i*3)\n",
    "    plt.axis('off')\n",
    "    plt.title('Prediction',fontsize=5)\n",
    "    plt.imshow(to_image(overlayed(img[i], mask_prediction[i]), True))\n",
    "\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    img, mask = target_ds[randint(0, len(target_ds))]\n",
    "    img, mask = img.cuda().unsqueeze(0), mask.cuda().unsqueeze(0)\n",
    "    mask_prediction = SegmentationInference(unet, resize_to=128)(img) > 0.5\n",
    "\n",
    "\n",
    "imgs_grid = make_grid(torch.clamp(img, -1, 1), nrow=batch_size, padding=5)\n",
    "plt.figure(figsize=(9, 15.), dpi=250)\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.axis('off')\n",
    "plt.imshow(to_image(imgs_grid, True))\n",
    "plt.axis('off')\n",
    "plt.title('Ground truth')\n",
    "plt.imshow(to_image(overlayed(img, mask, channel=0), True))\n",
    "plt.subplot(133)\n",
    "plt.axis('off')\n",
    "plt.title('Prediction')\n",
    "plt.imshow(to_image(overlayed(img, mask_prediction), True))\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Raw model:\\n{}'.format(\n",
    "    model_metrics(SegmentationInference(unet, resize_to=128), segmentation_dl, stats=(F_max,))))\n",
    "print('Thresholded:\\n{}'.format(\n",
    "    model_metrics(Threshold(unet, thr=0.5, resize_to=128), segmentation_dl, stats=(IoU, accuracy))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = 'asodijofijsdlfna;weqxyxyyxxxxyyyxqyqqyqqxxy'\n",
    "print(words.replace('qxy','---'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73a2de835501816cf39e7b895a829738a13dd333298eaabd54f7fea657ab5a84"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('qxy_1.4.0_3.7': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
